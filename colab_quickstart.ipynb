{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc82d62",
   "metadata": {},
   "source": [
    "# WaveMesh-Diff - Google Colab Quick Start\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HoangNguyennnnnnn/WaveMeshDf/blob/main/colab_quickstart.ipynb)\n",
    "\n",
    "**3D Mesh Generation using Diffusion Models in Wavelet Domain**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Quick Overview\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. ‚úÖ Setup WaveMesh-Diff in Google Colab\n",
    "2. üß™ Test all 4 modules (Wavelet, U-Net, Diffusion, Multi-view)\n",
    "3. üìä Visualize sparse wavelet representation\n",
    "4. üé® Run quick demos\n",
    "\n",
    "**Estimated time: 10-15 minutes**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff926a1",
   "metadata": {},
   "source": [
    "## üöÄ Setup\n",
    "\n",
    "### 1. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/HoangNguyennnnnnn/WaveMeshDf.git\n",
    "%cd WaveMeshDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd7919",
   "metadata": {},
   "source": [
    "### 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f671bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√†i dependencies c∆° b·∫£n\n",
    "!pip install -q PyWavelets trimesh matplotlib rtree scipy\n",
    "\n",
    "# PyTorch th∆∞·ªùng ƒë√£ c√≥ s·∫µn trong Colab\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f69c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√†i th√™m scikit-image cho marching cubes\n",
    "!pip install -q scikit-image\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d098a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick verification - check imports work\n",
    "try:\n",
    "    import pywt\n",
    "    import trimesh\n",
    "    import matplotlib\n",
    "    from skimage import measure\n",
    "    print(\"‚úÖ PyWavelets:\", pywt.__version__)\n",
    "    print(\"‚úÖ Trimesh:\", trimesh.__version__)\n",
    "    print(\"‚úÖ Matplotlib:\", matplotlib.__version__)\n",
    "    print(\"‚úÖ scikit-image: OK\")\n",
    "    print(\"\\nüéâ All core dependencies ready!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Missing dependency: {e}\")\n",
    "    print(\"Run the install cells above to fix this.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf64352",
   "metadata": {},
   "source": [
    "### 3. Optional: Install Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa9c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√†i transformers cho DINOv2 (t√πy ch·ªçn - c·∫£i thi·ªán quality)\n",
    "!pip install -q transformers huggingface_hub\n",
    "\n",
    "# Login HuggingFace (c·∫ßn token t·ª´ https://huggingface.co/settings/tokens)\n",
    "# from huggingface_hub import login\n",
    "# login(token=\"your_token_here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec19aa53",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Test Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf8f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test t·∫•t c·∫£ modules\n",
    "!python test_all_modules.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a1c53e",
   "metadata": {},
   "source": [
    "**Note:** N·∫øu g·∫∑p l·ªói import, restart runtime v√† ch·∫°y l·∫°i t·ª´ ƒë·∫ßu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860746b",
   "metadata": {},
   "source": [
    "**K·ª≥ v·ªçng:**\n",
    "```\n",
    "Results: 4/4 modules passed\n",
    "  Module A ‚úÖ PASS\n",
    "  Module B ‚úÖ PASS\n",
    "  Module C ‚úÖ PASS\n",
    "  Module D ‚úÖ PASS\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7613713d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Quick Demo\n",
    "\n",
    "### Module A: Wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.wavelet_utils import mesh_to_sdf_simple, sdf_to_sparse_wavelet, sparse_wavelet_to_sdf\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# T·∫°o mesh m·∫´u\n",
    "mesh = trimesh.creation.box(extents=[1, 1, 1])\n",
    "print(f\"Mesh: {len(mesh.vertices)} vertices, {len(mesh.faces)} faces\")\n",
    "\n",
    "# Chuy·ªÉn sang SDF\n",
    "sdf = mesh_to_sdf_simple(mesh, resolution=32)\n",
    "print(f\"SDF shape: {sdf.shape}\")\n",
    "\n",
    "# Wavelet transform - tr·∫£ v·ªÅ dictionary\n",
    "sparse_data = sdf_to_sparse_wavelet(sdf, threshold=0.01)\n",
    "print(f\"Sparse indices: {sparse_data['indices'].shape}\")\n",
    "print(f\"Sparse features: {sparse_data['features'].shape}\")\n",
    "\n",
    "# Calculate sparsity\n",
    "total_elements = 32 ** 3\n",
    "non_zero = len(sparse_data['features'])\n",
    "sparsity = 100 * (1 - non_zero / total_elements)\n",
    "print(f\"Sparsity: {sparsity:.1f}%\")\n",
    "\n",
    "# Reconstruct\n",
    "sdf_recon = sparse_wavelet_to_sdf(sparse_data)\n",
    "mse = np.mean((sdf - sdf_recon) ** 2)\n",
    "print(f\"Reconstruction MSE: {mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779886df",
   "metadata": {},
   "source": [
    "### Visualize SDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee85529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SDF slice\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].imshow(sdf[16, :, :], cmap='RdBu')\n",
    "axes[0].set_title('Original SDF (slice)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(sdf_recon[16, :, :], cmap='RdBu')\n",
    "axes[1].set_title('Reconstructed SDF')\n",
    "axes[1].axis('off')\n",
    "\n",
    "diff = np.abs(sdf - sdf_recon)\n",
    "axes[2].imshow(diff[16, :, :], cmap='hot')\n",
    "axes[2].set_title(f'Error (MSE={mse:.6f})')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f179dc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Module D: Multi-view Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf1799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import create_multiview_encoder\n",
    "import torch\n",
    "\n",
    "# T·∫°o encoder\n",
    "encoder = create_multiview_encoder(preset='small')\n",
    "print(f\"Encoder created: {sum(p.numel() for p in encoder.parameters()):,} params\")\n",
    "\n",
    "# Test v·ªõi random data\n",
    "batch_size = 2\n",
    "num_views = 4\n",
    "images = torch.randn(batch_size, num_views, 3, 224, 224)\n",
    "poses = torch.randn(batch_size, num_views, 3, 4)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    conditioning = encoder(images, poses)\n",
    "\n",
    "print(f\"Input images: {images.shape}\")\n",
    "print(f\"Input poses: {poses.shape}\")\n",
    "print(f\"Output conditioning: {conditioning.shape}\")\n",
    "print(\"‚úÖ Multi-view encoder working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4440e715",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Module B + C: U-Net + Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import WaveMeshUNet, GaussianDiffusion\n",
    "\n",
    "# T·∫°o U-Net\n",
    "unet = WaveMeshUNet(\n",
    "    in_channels=1,\n",
    "    encoder_channels=[16, 32, 64],\n",
    "    decoder_channels=[64, 32, 16],\n",
    "    time_emb_dim=128,\n",
    "    use_attention=True,\n",
    "    context_dim=384  # Match Module D output\n",
    ")\n",
    "print(f\"U-Net: {sum(p.numel() for p in unet.parameters()):,} params\")\n",
    "\n",
    "# T·∫°o Diffusion\n",
    "diffusion = GaussianDiffusion(\n",
    "    timesteps=1000,\n",
    "    beta_schedule='linear'\n",
    ")\n",
    "print(f\"Diffusion: {diffusion.timesteps} timesteps\")\n",
    "print(f\"Beta range: [{diffusion.betas[0]:.6f}, {diffusion.betas[-1]:.6f}]\")\n",
    "print(\"‚úÖ U-Net + Diffusion ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677194c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Download Data\n",
    "\n",
    "### Option 1: ModelNet40 (Quick - 500MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e2c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ModelNet40\n",
    "!python scripts/download_data.py --dataset modelnet40\n",
    "\n",
    "# Check downloaded data\n",
    "!ls -lh data/ModelNet40/ 2>/dev/null || echo \"Data downloading... Check scripts/download_data.py for manual instructions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd1bda4",
   "metadata": {},
   "source": [
    "### Option 2: ShapeNet (Manual)\n",
    "\n",
    "ƒê·ªÉ download ShapeNet:\n",
    "1. ƒêƒÉng k√Ω t·∫°i https://shapenet.org/\n",
    "2. Download ShapeNetCore.v2\n",
    "3. Upload l√™n Google Drive\n",
    "4. Mount Drive v√† copy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be9c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copy ShapeNet data (n·∫øu ƒë√£ c√≥ trong Drive)\n",
    "# !cp -r /content/drive/MyDrive/ShapeNetCore.v2 ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2443e8af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé® Visualize Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275808c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize complete pipeline\n",
    "# Note: visualize_results.py c·∫ßn ƒë∆∞·ª£c t·∫°o tr∆∞·ªõc\n",
    "# Ho·∫∑c d√πng code ƒë∆°n gi·∫£n d∆∞·ªõi ƒë√¢y:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from data.wavelet_utils import WaveletTransform3D\n",
    "import numpy as np\n",
    "\n",
    "# Simple visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('WaveMesh-Diff Pipeline Overview', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Input SDF\n",
    "axes[0, 0].imshow(sdf[16, :, :], cmap='RdBu')\n",
    "axes[0, 0].set_title('1. Input SDF (slice)')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# 2. Wavelet Coefficients (visualize sparsity)\n",
    "sparse_indices = sparse_data['indices']\n",
    "sparse_viz = np.zeros((32, 32))\n",
    "for idx in sparse_indices:\n",
    "    if idx[2] == 16:  # Same slice\n",
    "        sparse_viz[idx[0], idx[1]] += 1\n",
    "axes[0, 1].imshow(sparse_viz, cmap='hot')\n",
    "axes[0, 1].set_title(f'2. Sparse Wavelet ({sparsity:.1f}% sparse)')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# 3. Reconstructed SDF\n",
    "axes[1, 0].imshow(sdf_recon[16, :, :], cmap='RdBu')\n",
    "axes[1, 0].set_title('3. Reconstructed SDF')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# 4. Reconstruction Error\n",
    "error = np.abs(sdf - sdf_recon)\n",
    "axes[1, 1].imshow(error[16, :, :], cmap='Reds')\n",
    "axes[1, 1].set_title(f'4. Error (MSE={mse:.6f})')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"‚úÖ Pipeline visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309aaba6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèãÔ∏è Training Example (Conceptual)\n",
    "\n",
    "‚ö†Ô∏è **L∆∞u √Ω:** Training ƒë·∫ßy ƒë·ªß c·∫ßn nhi·ªÅu th·ªùi gian v√† GPU. Xem `ROADMAP.md` ƒë·ªÉ c√≥ code ƒë·∫ßy ƒë·ªß."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd73baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (conceptual)\n",
    "# Xem ROADMAP.md ƒë·ªÉ c√≥ implementation ƒë·∫ßy ƒë·ªß\n",
    "\n",
    "from models import create_multiview_encoder, WaveMeshUNet, GaussianDiffusion\n",
    "import torch\n",
    "\n",
    "# 1. Prepare models\n",
    "encoder = create_multiview_encoder(preset='small')\n",
    "unet = WaveMeshUNet(\n",
    "    in_channels=1,\n",
    "    encoder_channels=[16, 32, 64],\n",
    "    decoder_channels=[64, 32, 16],\n",
    "    time_emb_dim=128,\n",
    "    context_dim=384\n",
    ")\n",
    "diffusion = GaussianDiffusion(timesteps=1000)\n",
    "\n",
    "# 2. Optimizer\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': encoder.parameters(), 'lr': 1e-5},\n",
    "    {'params': unet.parameters(), 'lr': 1e-4}\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Training setup ready!\")\n",
    "print(f\"Encoder params: {sum(p.numel() for p in encoder.parameters()):,}\")\n",
    "print(f\"U-Net params: {sum(p.numel() for p in unet.parameters()):,}\")\n",
    "print(\"\\nüìñ See ROADMAP.md for full training code with:\")\n",
    "print(\"  ‚Ä¢ Dataset implementation\")\n",
    "print(\"  ‚Ä¢ Training loop\")\n",
    "print(\"  ‚Ä¢ Evaluation metrics\")\n",
    "print(\"  ‚Ä¢ Checkpointing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c9995",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Next Steps\n",
    "\n",
    "1. **ƒê·ªçc Documentation:**\n",
    "   - [README.md](README.md) - Project overview\n",
    "   - [QUICKSTART.md](QUICKSTART.md) - Quick start guide\n",
    "   - [ROADMAP.md](ROADMAP.md) - Training roadmap\n",
    "   - [ARCHITECTURE.md](ARCHITECTURE.md) - Technical details\n",
    "\n",
    "2. **Download Data:**\n",
    "   - ModelNet40 (500MB) - Quick start\n",
    "   - ShapeNet (50GB) - Better quality\n",
    "\n",
    "3. **Train Model:**\n",
    "   - Xem `ROADMAP.md` ƒë·ªÉ c√≥ training code ƒë·∫ßy ƒë·ªß\n",
    "   - Implement dataset loader\n",
    "   - Run training loop\n",
    "\n",
    "4. **Improve:**\n",
    "   - Mixed precision training\n",
    "   - Classifier-free guidance\n",
    "   - EMA for better quality\n",
    "\n",
    "---\n",
    "\n",
    "## üêõ Troubleshooting\n",
    "\n",
    "### \"ModuleNotFoundError: No module named 'pywt'\"\n",
    "```python\n",
    "!pip install PyWavelets\n",
    "```\n",
    "\n",
    "### \"ModuleNotFoundError: No module named 'rtree'\"\n",
    "```python\n",
    "!pip install rtree\n",
    "```\n",
    "\n",
    "### \"ValueError: too many values to unpack (expected 2)\"\n",
    "L·ªói n√†y x·∫£y ra khi d√πng API c≈©. `sdf_to_sparse_wavelet()` tr·∫£ v·ªÅ **dictionary**, kh√¥ng ph·∫£i tuple:\n",
    "```python\n",
    "# ‚ùå Sai:\n",
    "coeffs, coords = sdf_to_sparse_wavelet(sdf)\n",
    "\n",
    "# ‚úÖ ƒê√∫ng:\n",
    "sparse_data = sdf_to_sparse_wavelet(sdf, threshold=0.01)\n",
    "print(sparse_data['indices'].shape)\n",
    "print(sparse_data['features'].shape)\n",
    "```\n",
    "\n",
    "### \"CUDA out of memory\"\n",
    "```python\n",
    "# Gi·∫£m batch size ho·∫∑c resolution\n",
    "batch_size = 2\n",
    "resolution = 16\n",
    "```\n",
    "\n",
    "### \"transformers not available\"\n",
    "```python\n",
    "!pip install transformers huggingface_hub\n",
    "# Code s·∫Ω t·ª± ƒë·ªông fallback sang CNN n·∫øu kh√¥ng c√≥\n",
    "```\n",
    "\n",
    "### \"No module named 'skimage'\"\n",
    "```python\n",
    "!pip install scikit-image\n",
    "```\n",
    "\n",
    "Xem ƒë·∫ßy ƒë·ªß t·∫°i [TROUBLESHOOTING.md](TROUBLESHOOTING.md).\n",
    "\n",
    "---\n",
    "\n",
    "**Happy 3D Generation! üé®**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
