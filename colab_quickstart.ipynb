{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff926a1",
   "metadata": {},
   "source": [
    "## üöÄ Setup\n",
    "\n",
    "### 1. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/HoangNguyennnnnnn/WaveMeshDf.git\n",
    "%cd WaveMeshDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd7919",
   "metadata": {},
   "source": [
    "### 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f671bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√†i dependencies c∆° b·∫£n\n",
    "!pip install -q PyWavelets trimesh matplotlib\n",
    "\n",
    "# PyTorch th∆∞·ªùng ƒë√£ c√≥ s·∫µn trong Colab\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf64352",
   "metadata": {},
   "source": [
    "### 3. Optional: Install Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa9c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√†i transformers cho DINOv2 (t√πy ch·ªçn - c·∫£i thi·ªán quality)\n",
    "!pip install -q transformers huggingface_hub\n",
    "\n",
    "# Login HuggingFace (c·∫ßn token t·ª´ https://huggingface.co/settings/tokens)\n",
    "# from huggingface_hub import login\n",
    "# login(token=\"your_token_here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec19aa53",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Test Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf8f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test t·∫•t c·∫£ modules\n",
    "!python test_all_modules.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860746b",
   "metadata": {},
   "source": [
    "**K·ª≥ v·ªçng:**\n",
    "```\n",
    "Results: 4/4 modules passed\n",
    "  Module A ‚úÖ PASS\n",
    "  Module B ‚úÖ PASS\n",
    "  Module C ‚úÖ PASS\n",
    "  Module D ‚úÖ PASS\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7613713d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Quick Demo\n",
    "\n",
    "### Module A: Wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import mesh_to_sdf_simple, sdf_to_sparse_wavelet, sparse_wavelet_to_sdf\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# T·∫°o mesh m·∫´u\n",
    "mesh = trimesh.creation.box(extents=[1, 1, 1])\n",
    "print(f\"Mesh: {len(mesh.vertices)} vertices, {len(mesh.faces)} faces\")\n",
    "\n",
    "# Chuy·ªÉn sang SDF\n",
    "sdf = mesh_to_sdf_simple(mesh, resolution=32)\n",
    "print(f\"SDF shape: {sdf.shape}\")\n",
    "\n",
    "# Wavelet transform\n",
    "coeffs, coords = sdf_to_sparse_wavelet(sdf, threshold=0.01)\n",
    "print(f\"Sparse coefficients: {coeffs.shape}\")\n",
    "print(f\"Sparsity: {100 * (1 - len(coeffs) / (32**3)):.1f}%\")\n",
    "\n",
    "# Reconstruct\n",
    "sdf_recon = sparse_wavelet_to_sdf(coeffs, coords, shape=(32, 32, 32))\n",
    "mse = np.mean((sdf - sdf_recon) ** 2)\n",
    "print(f\"Reconstruction MSE: {mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779886df",
   "metadata": {},
   "source": [
    "### Visualize SDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee85529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SDF slice\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].imshow(sdf[16, :, :], cmap='RdBu')\n",
    "axes[0].set_title('Original SDF (slice)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(sdf_recon[16, :, :], cmap='RdBu')\n",
    "axes[1].set_title('Reconstructed SDF')\n",
    "axes[1].axis('off')\n",
    "\n",
    "diff = np.abs(sdf - sdf_recon)\n",
    "axes[2].imshow(diff[16, :, :], cmap='hot')\n",
    "axes[2].set_title(f'Error (MSE={mse:.6f})')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f179dc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Module D: Multi-view Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf1799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import create_multiview_encoder\n",
    "import torch\n",
    "\n",
    "# T·∫°o encoder\n",
    "encoder = create_multiview_encoder(preset='small')\n",
    "print(f\"Encoder created: {sum(p.numel() for p in encoder.parameters()):,} params\")\n",
    "\n",
    "# Test v·ªõi random data\n",
    "batch_size = 2\n",
    "num_views = 4\n",
    "images = torch.randn(batch_size, num_views, 3, 224, 224)\n",
    "poses = torch.randn(batch_size, num_views, 3, 4)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    conditioning = encoder(images, poses)\n",
    "\n",
    "print(f\"Input images: {images.shape}\")\n",
    "print(f\"Input poses: {poses.shape}\")\n",
    "print(f\"Output conditioning: {conditioning.shape}\")\n",
    "print(\"‚úÖ Multi-view encoder working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4440e715",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Module B + C: U-Net + Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import WaveMeshUNet, GaussianDiffusion\n",
    "\n",
    "# T·∫°o U-Net\n",
    "unet = WaveMeshUNet(\n",
    "    in_channels=1,\n",
    "    encoder_channels=[16, 32, 64],\n",
    "    decoder_channels=[64, 32, 16],\n",
    "    time_emb_dim=128,\n",
    "    use_attention=True,\n",
    "    context_dim=384  # Match Module D output\n",
    ")\n",
    "print(f\"U-Net: {sum(p.numel() for p in unet.parameters()):,} params\")\n",
    "\n",
    "# T·∫°o Diffusion\n",
    "diffusion = GaussianDiffusion(\n",
    "    timesteps=1000,\n",
    "    beta_schedule='linear'\n",
    ")\n",
    "print(f\"Diffusion: {diffusion.timesteps} timesteps\")\n",
    "print(f\"Beta range: [{diffusion.betas[0]:.6f}, {diffusion.betas[-1]:.6f}]\")\n",
    "print(\"‚úÖ U-Net + Diffusion ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677194c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Download Data\n",
    "\n",
    "### Option 1: ModelNet40 (Quick - 500MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e2c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ModelNet40\n",
    "!python scripts/download_data.py --dataset modelnet40\n",
    "\n",
    "# Check downloaded data\n",
    "!ls -lh data/ModelNet40/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd1bda4",
   "metadata": {},
   "source": [
    "### Option 2: ShapeNet (Manual)\n",
    "\n",
    "ƒê·ªÉ download ShapeNet:\n",
    "1. ƒêƒÉng k√Ω t·∫°i https://shapenet.org/\n",
    "2. Download ShapeNetCore.v2\n",
    "3. Upload l√™n Google Drive\n",
    "4. Mount Drive v√† copy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be9c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copy ShapeNet data (n·∫øu ƒë√£ c√≥ trong Drive)\n",
    "# !cp -r /content/drive/MyDrive/ShapeNetCore.v2 ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2443e8af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé® Visualize Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275808c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize complete pipeline\n",
    "!python visualize_results.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309aaba6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèãÔ∏è Training Example (Conceptual)\n",
    "\n",
    "‚ö†Ô∏è **L∆∞u √Ω:** Training ƒë·∫ßy ƒë·ªß c·∫ßn nhi·ªÅu th·ªùi gian v√† GPU. Xem `ROADMAP.md` ƒë·ªÉ c√≥ code ƒë·∫ßy ƒë·ªß."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd73baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (conceptual)\n",
    "# Xem ROADMAP.md ƒë·ªÉ c√≥ implementation ƒë·∫ßy ƒë·ªß\n",
    "\n",
    "# 1. Prepare models\n",
    "encoder = create_multiview_encoder(preset='small')\n",
    "unet = WaveMeshUNet(context_dim=384)\n",
    "diffusion = GaussianDiffusion()\n",
    "\n",
    "# 2. Optimizer\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': encoder.parameters(), 'lr': 1e-5},\n",
    "    {'params': unet.parameters(), 'lr': 1e-4}\n",
    "])\n",
    "\n",
    "# 3. Training loop\n",
    "# for batch in dataloader:\n",
    "#     conditioning = encoder(batch['images'], batch['poses'])\n",
    "#     loss = diffusion(batch['coeffs'], context=conditioning)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "print(\"‚úÖ Training setup ready!\")\n",
    "print(\"See ROADMAP.md for full training code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c9995",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Next Steps\n",
    "\n",
    "1. **ƒê·ªçc Documentation:**\n",
    "   - [README.md](README.md) - Project overview\n",
    "   - [QUICKSTART.md](QUICKSTART.md) - Quick start guide\n",
    "   - [ROADMAP.md](ROADMAP.md) - Training roadmap\n",
    "   - [ARCHITECTURE.md](ARCHITECTURE.md) - Technical details\n",
    "\n",
    "2. **Download Data:**\n",
    "   - ModelNet40 (500MB) - Quick start\n",
    "   - ShapeNet (50GB) - Better quality\n",
    "\n",
    "3. **Train Model:**\n",
    "   - Xem `ROADMAP.md` ƒë·ªÉ c√≥ training code ƒë·∫ßy ƒë·ªß\n",
    "   - Implement dataset loader\n",
    "   - Run training loop\n",
    "\n",
    "4. **Improve:**\n",
    "   - Mixed precision training\n",
    "   - Classifier-free guidance\n",
    "   - EMA for better quality\n",
    "\n",
    "---\n",
    "\n",
    "## üêõ Troubleshooting\n",
    "\n",
    "### \"ModuleNotFoundError: No module named 'pywt'\"\n",
    "```python\n",
    "!pip install PyWavelets\n",
    "```\n",
    "\n",
    "### \"CUDA out of memory\"\n",
    "```python\n",
    "# Gi·∫£m batch size ho·∫∑c resolution\n",
    "batch_size = 2\n",
    "resolution = 16\n",
    "```\n",
    "\n",
    "### \"transformers not available\"\n",
    "```python\n",
    "!pip install transformers huggingface_hub\n",
    "# Code s·∫Ω t·ª± ƒë·ªông fallback sang CNN n·∫øu kh√¥ng c√≥\n",
    "```\n",
    "\n",
    "Xem ƒë·∫ßy ƒë·ªß t·∫°i [TROUBLESHOOTING.md](TROUBLESHOOTING.md).\n",
    "\n",
    "---\n",
    "\n",
    "**Happy 3D Generation! üé®**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
