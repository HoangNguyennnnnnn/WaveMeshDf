# Google Colab Compatibility - Quick Start

## ‚úÖ What's New

**All three modules (A, B, C) now work in Google Colab!**

No more spconv compilation errors. The system automatically falls back to dense PyTorch operations when spconv isn't available.

## üöÄ Quick Test

Copy this into a Google Colab cell:

```python
# Clone and setup
!git clone <your-repo-url> wavemesh
%cd wavemesh
!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install -q PyWavelets pillow pyyaml

# Test all modules
import torch
from models import WaveMeshUNet, GaussianDiffusion
from models.spconv_compat import get_backend_info, sparse_tensor

# Check backend
info = get_backend_info()
print(f"‚úÖ Using {info['backend']}")
print(f"üìä Performance: {info['performance']}")

# Create a small model (Module B)
model = WaveMeshUNet(
    in_channels=1,
    out_channels=1,
    encoder_channels=[16, 32, 64],
    decoder_channels=[64, 32, 16],
    use_attention=False
)
print(f"‚úÖ Created WaveMeshUNet with {sum(p.numel() for p in model.parameters()):,} parameters")

# Test forward pass
batch_size = 1
num_points = 50
features = torch.randn(num_points, 1)
indices = torch.cat([
    torch.zeros(num_points, 1, dtype=torch.long),
    torch.randint(0, 16, (num_points, 3))
], dim=1)
sp_input = sparse_tensor(features, indices, (16, 16, 16), batch_size)
timesteps = torch.zeros(batch_size, dtype=torch.long)

with torch.no_grad():
    output = model(sp_input, timesteps)

print(f"‚úÖ Forward pass successful!")
print(f"Input: {sp_input.features.shape}, Output: {output.features.shape}")
```

## üìä Performance Comparison

| Module   | Colab (fallback) | Local GPU (spconv) | Speed Difference |
| -------- | ---------------- | ------------------ | ---------------- |
| Module A | Full speed       | Full speed         | 1x               |
| Module B | Functional       | Optimized          | ~10-50x slower   |
| Module C | Functional       | Optimized          | ~10-50x slower   |

**Recommendation:**

- **Learning/Testing**: Use Colab - easy, no setup required
- **Training/Production**: Use local GPU with spconv - much faster

## üîß How It Works

The system automatically detects if spconv is available:

```python
if spconv is available:
    ‚ö° Use native spconv (fast, optimized)
else:
    üîÑ Use dense PyTorch fallback (slower but functional)
```

Your code works the same either way - no changes needed!

## üìù What Changed

1. **`models/spconv_compat.py`** - New compatibility layer (auto-imported)
2. **`models/unet_sparse.py`** - Updated imports (transparent to users)
3. **Colab guides** - Updated to reflect full compatibility

## ‚ùì FAQ

**Q: Do I need to change my code?**  
A: No! The compatibility layer provides the same API as spconv.

**Q: Why is it slower in Colab?**  
A: Dense operations process the entire 3D grid instead of just sparse points. This is the trade-off for avoiding compilation.

**Q: Can I use Module A (dense) at full speed?**  
A: Yes! Module A uses standard PyTorch operations and runs at full speed everywhere.

**Q: Should I install spconv in Colab?**  
A: No - it causes compilation errors. Let the automatic fallback handle it.

**Q: Can I switch between spconv and fallback?**  
A: Yes! Install/uninstall spconv and the system auto-detects. Your code doesn't change.

## üéØ Next Steps

1. Open the [full Colab guide](COLAB_GUIDE.md) for detailed setup
2. Try the test cells to verify all modules work
3. For production training, see [QUICKSTART.md](QUICKSTART.md) for local GPU setup

## üêõ Troubleshooting

**"Module not found" errors:**

```python
# Make sure you're in the repo directory
%cd wavemesh
import sys
sys.path.insert(0, '.')
```

**Out of memory:**

```python
# Use smaller models for Colab
encoder_channels = [8, 16, 32]  # Instead of [32, 64, 128, 256]
decoder_channels = [32, 16, 8]  # Instead of [256, 128, 64, 32]
```

**Want to see which backend is active:**

```python
from models.spconv_compat import get_backend_info
print(get_backend_info())
```

## üìö Documentation

- **[COLAB_GUIDE.md](COLAB_GUIDE.md)** - Complete Colab setup and testing
- **[COLAB_COMPATIBILITY.md](COLAB_COMPATIBILITY.md)** - Technical details
- **[IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md)** - How we built it
- **[README.md](README.md)** - Full project documentation

---

**Happy experimenting in Colab! üéâ**
